---
layout: archive
author_profile: true
title: Privacy
permalink: /privacy/
---

{: .text-justify}
*Multi-Armed Bandit (MAB)* is a basic framework for the sequential decisionmaking problem, where a decision-maker (or player) must select an arm from a set of arms with unknown distribution at each time round. After that, the player will observe a reward from the environment. According to the rewarding process,
MABs can be roughly classified into stochastic MABs, adversarial MABs, Markovian MABs, and Contextual MABs.

   ![test](https://github.com/jwentong/jwentong.github.io/raw/master/assets/images/mabfig_02.jpg)

### Theoretical Parts

####  1. Stochatic MABs

{: .text-justify}
* IEEE Transaction on Wireless Communications
* IEEE Transaction on Communications
* IEEE Transaction on Vehicular Technology 
* IEEE Transaction on Cognitive Communications and Networking 
* IEEE Communications Magazine  
* IEEE Transactions on Mobile Computing 
* IEEE Journal on Selected Areas in Communications  
* IEEE Communications Letters 
* IEEE Wireless Communications Letters 
* Journal of Communications and Information Networks
* Conferences ICC, VTC, WCNC, GLOBECOM, INFOCOM
